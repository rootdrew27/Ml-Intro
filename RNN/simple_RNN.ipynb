{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 unique words found\n"
     ]
    }
   ],
   "source": [
    "from data import train_data, test_data\n",
    "\n",
    "#create vocab (data corpus) \n",
    "vocab = list(set([w for text in train_data.keys() for w in text.split(' ')]))\n",
    "vocab_size = len(vocab)\n",
    "print(\"%d unique words found\" % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "is\n"
     ]
    }
   ],
   "source": [
    "#Assign indices to each word\n",
    "word_to_idx = {w: i for i, w in enumerate(vocab)}\n",
    "idx_to_word = {i: w for i, w in enumerate(vocab)}\n",
    "\n",
    "#test it\n",
    "print(word_to_idx['good'])\n",
    "print(idx_to_word[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encoding\n",
    "import numpy as np\n",
    "\n",
    "def createInputs(datum) -> list[int]:\n",
    "    \"\"\"Creates an array of one-hot vectors for a datum \n",
    "\n",
    "    Args:\n",
    "        datum (str): a particular datum from the train_data \n",
    "    \"\"\"\n",
    "    inputs = []\n",
    "    for word in datum.split(' '):\n",
    "        tmp_arr = np.zeros((vocab_size, 1)) #create an 18 x 1 vector for each word\n",
    "        tmp_arr[word_to_idx[word]] = 1\n",
    "        inputs.append(tmp_arr)\n",
    "    return inputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randn\n",
    "\n",
    "class RNN:\n",
    "\n",
    "    def __init__(self, input_size, output_size, hidden_size=64):\n",
    "        self.Whh = randn(hidden_size, hidden_size) / 1000\n",
    "        self.Wxh = randn(hidden_size, input_size) / 1000\n",
    "        self.Why = randn(output_size, hidden_size) / 1000\n",
    "\n",
    "        self.bh = np.zeros((hidden_size, 1))\n",
    "        self.by = np.zeros((output_size, 1))\n",
    "\n",
    "    def forward(self, inputs : list[list[int]]):\n",
    "        \"\"\"Perform forward pass of the RNN using the given inputs.\n",
    "        Returns the final output and hidden state.\n",
    "\n",
    "        Args:\n",
    "            inputs list[list[int]]: one-hot input vectors\n",
    "        \"\"\"\n",
    "\n",
    "        h = np.zeros((self.Whh.shape[0], 1))\n",
    "\n",
    "        for i, x in enumerate(inputs):\n",
    "            h = np.tanh(self.Wxh @ x + self.Whh @ h + self.bh)\n",
    "\n",
    "        y = self.Why @ h + self.by\n",
    "\n",
    "        return y, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(xs):\n",
    "    return np.exp(xs) / sum(np.exp(xs))\n",
    "\n",
    "rnn = RNN(vocab_size, 2)\n",
    "\n",
    "inputs = createInputs('i am very good')\n",
    "out, h = rnn.forward(inputs)\n",
    "probs = softmax(out)\n",
    "print(probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
